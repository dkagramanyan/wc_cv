{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2690cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from skimage import io, filters\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "import copy\n",
    "import time\n",
    "\n",
    "from mpire import WorkerPool\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib import cm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "from combra import stats as cstats\n",
    "from combra import approx as capprox\n",
    "from combra import image as cimage\n",
    "from combra import contours as ccontours\n",
    "\n",
    "from numba import njit\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from combra.tests import test_fractal_dimensions\n",
    "from combra.contours import contour_to_binary_mask, scale_contour, draw_contours\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cafe0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = img[400:-400,1300:-1300]\n",
    "    _, binary = cv2.threshold(img, 0, 255, cv2.THRESH_OTSU)\n",
    "\n",
    "    cnts, _ = cv2.findContours(binary, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    return binary, cnts\n",
    "\n",
    "\n",
    "# --- Group images by number ranges (1-500, 501-1000, ...) ---\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "\n",
    "def _extract_image_number(p):\n",
    "    stem = Path(p).stem\n",
    "    m = re.search(r\"(\\d+)\", stem)\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "\n",
    "images_dir = Path(\"data/autumn/images\")\n",
    "all_image_paths = [p for p in images_dir.glob(\"*.JPG\") if re.fullmatch(r\"\\d+\", p.stem)]\n",
    "all_image_paths = sorted(\n",
    "    all_image_paths,\n",
    "    key=lambda p: _extract_image_number(p) or 0,\n",
    ")\n",
    "\n",
    "# If you also have .jpg/.jpeg, uncomment:\n",
    "# all_image_paths += list(images_dir.glob(\"*.jpg\")) + list(images_dir.glob(\"*.jpeg\"))\n",
    "\n",
    "group_size = 250\n",
    "_groups = {}\n",
    "\n",
    "for p in all_image_paths:\n",
    "    n = _extract_image_number(p)\n",
    "    if n is None:\n",
    "        continue\n",
    "    g_start = ((n - 1) // group_size) * group_size + 1\n",
    "    g_end = g_start + group_size - 1\n",
    "    label = f\"{g_start:04d}-{g_end:04d}\"\n",
    "    _groups.setdefault(label, []).append(str(p))\n",
    "\n",
    "# Sorted list of (label, [image_path, ...])\n",
    "image_groups = sorted(\n",
    "    _groups.items(),\n",
    "    key=lambda kv: int(kv[0].split(\"-\")[0]),\n",
    ")\n",
    "\n",
    "group_labels = [label for label, _ in image_groups]\n",
    "\n",
    "print(f\"Found {len(all_image_paths)} images, grouped into {len(image_groups)} groups\")\n",
    "if image_groups:\n",
    "    print(\"First 5 groups:\", [(k, len(v)) for k, v in image_groups[:20]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d5bde8",
   "metadata": {},
   "source": [
    "# Fractal dimention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefd2fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = 2 ** np.arange(1, 10)\n",
    "test_fractal_dimensions(sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b43b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs=20\n",
    "\n",
    "\n",
    "n_images_list = []\n",
    "n_contours_list = []\n",
    "n_contours_fd_list = []\n",
    "\n",
    "# Stream results directly to parquet to keep memory bounded\n",
    "out_path = Path(\"poliamid_group_250.parquet\")\n",
    "\n",
    "schema = pa.schema(\n",
    "    [\n",
    "        (\"group_label\", pa.string()),\n",
    "        (\"n_images\", pa.int32()),\n",
    "        (\"n_contours_total\", pa.int32()),\n",
    "        (\"n_contours_fd\", pa.int32()),\n",
    "        (\"fd_list\", pa.list_(pa.float64())),\n",
    "        (\"len_nodes_list\", pa.list_(pa.int32())),\n",
    "        (\"len_pixels_list\", pa.list_(pa.float64())),\n",
    "        (\"area_list\", pa.list_(pa.float64())),\n",
    "        (\"n_jobs\", pa.int32()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "writer = pq.ParquetWriter(out_path, schema, compression=\"zstd\")\n",
    "\n",
    "\n",
    "def _metrics_for_image(image_path):\n",
    "    # Compute metrics inside the worker to avoid returning huge contour objects\n",
    "    _, contours = preprocess_image(image_path)\n",
    "\n",
    "    n_total = len(contours)\n",
    "\n",
    "    fd_list = []\n",
    "    ln_list = []\n",
    "    lp_list = []\n",
    "    ar_list = []\n",
    "\n",
    "    for c in contours:\n",
    "        fd = cimage.contour_fractal_dimension(c)\n",
    "        if fd is None:\n",
    "            continue\n",
    "        fd_list.append(float(fd))\n",
    "        ln_list.append(int(len(c)))\n",
    "        lp_list.append(float(cv2.arcLength(c, closed=True)))\n",
    "        ar_list.append(float(cv2.contourArea(c)))\n",
    "\n",
    "    return n_total, fd_list, ln_list, lp_list, ar_list\n",
    "\n",
    "\n",
    "with WorkerPool(n_jobs=n_jobs, use_dill=False) as pool:\n",
    "    for idx, (group_label, group_paths) in tqdm(enumerate(image_groups)):\n",
    "\n",
    "        total_contours = 0\n",
    "        fd_list = []\n",
    "        ln_list = []\n",
    "        lp_list = []\n",
    "        ar_list = []\n",
    "\n",
    "        # Process per-image in parallel and stream results back (keeps memory bounded)\n",
    "        for n_total, fds, lns, lps, ars in pool.imap_unordered(\n",
    "            _metrics_for_image,\n",
    "            group_paths,\n",
    "            progress_bar=True,\n",
    "            chunk_size=1,\n",
    "        ):\n",
    "            total_contours += int(n_total)\n",
    "            fd_list.extend(fds)\n",
    "            ln_list.extend(lns)\n",
    "            lp_list.extend(lps)\n",
    "            ar_list.extend(ars)\n",
    "\n",
    "        # Keep some diagnostics\n",
    "        n_images_list.append(len(group_paths))\n",
    "        n_contours_list.append(total_contours)\n",
    "        n_contours_fd_list.append(len(fd_list))\n",
    "\n",
    "        # Write one row per group (keeps RAM bounded)\n",
    "        row = pa.table(\n",
    "            {\n",
    "                \"group_label\": pa.array([group_label], type=pa.string()),\n",
    "                \"n_images\": pa.array([len(group_paths)], type=pa.int32()),\n",
    "                \"n_contours_total\": pa.array([total_contours], type=pa.int32()),\n",
    "                \"n_contours_fd\": pa.array([len(fd_list)], type=pa.int32()),\n",
    "                \"fd_list\": pa.array([fd_list], type=pa.list_(pa.float64())),\n",
    "                \"len_nodes_list\": pa.array([ln_list], type=pa.list_(pa.int32())),\n",
    "                \"len_pixels_list\": pa.array([lp_list], type=pa.list_(pa.float64())),\n",
    "                \"area_list\": pa.array([ar_list], type=pa.list_(pa.float64())),\n",
    "                \"n_jobs\": pa.array([n_jobs], type=pa.int32()),\n",
    "            },\n",
    "            schema=schema,\n",
    "        )\n",
    "        writer.write_table(row)\n",
    "\n",
    "# Close parquet writer\n",
    "writer.close()\n",
    "print(\"Saved:\", out_path.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee76de39",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = image_groups[0][1][100]\n",
    "\n",
    "\n",
    "_, cnts = preprocess_image(img_path)\n",
    "\n",
    "# 56 \n",
    "# 11\n",
    "contour = cnts[11]\n",
    "\n",
    "binary = contour_to_binary_mask(contour, thickness=1)\n",
    "\n",
    "print(len(contour))\n",
    "plt.imshow(binary, cmap='gray')\n",
    "plt.savefig('binary.jpg', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "sizes, scale = cimage.valid_box_sizes_from_shape(binary.shape)\n",
    "\n",
    "cnt_big = ccontours.scale_contour(contour, scale)\n",
    "\n",
    "binary_big = ccontours.contour_to_binary_mask(cnt_big, thickness=1)\n",
    "\n",
    "plt.imshow(binary_big, cmap='gray')\n",
    "plt.savefig('binary_big.jpg', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "D = cimage.image_fractal_dimension(binary_big, sizes)\n",
    "\n",
    "print(D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775c38d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Parquet generated by the fractal-dimension extraction cell\n",
    "in_path = Path(\"poliamid_group_250.parquet\")\n",
    "\n",
    "table = pq.read_table(in_path)\n",
    "data = table.to_pydict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c17a77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n = len(data[\"group_label\"])\n",
    "groups = [{k: data[k][i] for k in data.keys()} for i in range(n)]\n",
    "group_labels = [g[\"group_label\"] for g in groups]\n",
    "\n",
    "# bin size for stats_preprocess\n",
    "for step in tqdm([0.01, 0.05, 0.1, 0.2, 0.3]):\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 7))\n",
    "\n",
    "    # Colors per group (will cycle if many groups)\n",
    "    colors = plt.cm.tab20(np.linspace(0, 1, max(2, min(20, len(groups)))))\n",
    "\n",
    "    a_list = []\n",
    "\n",
    "    for idx, g in enumerate(groups):\n",
    "        fd_list = g.get(\"fd_list\", [])\n",
    "        if fd_list is None:\n",
    "            fd_list = []\n",
    "        else:\n",
    "            fd_list = list(fd_list)\n",
    "\n",
    "        color = colors[idx % len(colors)]\n",
    "\n",
    "        if not fd_list:\n",
    "            a_list.append(np.nan)\n",
    "            continue\n",
    "\n",
    "        x_orig, y_orig = cstats.stats_preprocess(fd_list, step)\n",
    "\n",
    "        # Exponential distribution only\n",
    "        (x_fit, y_fit), a, amp_exp = capprox.exponential_approx(\n",
    "            x_orig, y_orig, a=1, amp=1, x_lim=[1, 2], N=20\n",
    "        )\n",
    "        a_list.append(a)\n",
    "\n",
    "        label = (\n",
    "            # f\"{g['group_label']} | imgs={g.get('n_images', 0)} | cnts={g.get('n_contours', 0)} | a={a:.4f}\"\n",
    "            f\"{g['group_label']} | a={a:.4f}\"\n",
    "        )\n",
    "\n",
    "        axes[0].plot(x_fit, y_fit, '--', linewidth=2, color=color)\n",
    "        axes[0].plot(x_orig, y_orig, '-o', color=color, label=label)\n",
    "\n",
    "    axes[0].set_title(f'exponential fit, step={step}', fontsize=15)\n",
    "    axes[0].set_xlim(1, 2)\n",
    "    axes[0].set_ylim(1e-8, 1)\n",
    "    axes[0].set_yscale('log')\n",
    "    axes[0].set_ylabel('p(x)', fontsize=15)\n",
    "    axes[0].set_xlabel('fractal dimension', fontsize=15)\n",
    "    axes[0].legend(loc='upper right', fontsize=10)\n",
    "\n",
    "    # Diagnostics: parameter a per group\n",
    "    axes[1].plot(range(len(groups)), a_list, '-o', label='a')\n",
    "    axes[1].set_title(f'exponential parameter a, step={step}', fontsize=15)\n",
    "    axes[1].set_xticks(range(len(groups)))\n",
    "    axes[1].set_xticklabels(group_labels, rotation=45, fontsize=12, ha='right')\n",
    "    axes[1].legend(loc='upper right', fontsize=12)\n",
    "\n",
    "    plt.savefig(f'fractal_dimention_step={step}.jpg', bbox_inches='tight')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wc-cv",
   "language": "python",
   "name": "wc-cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
